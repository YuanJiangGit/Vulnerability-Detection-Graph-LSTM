# -*- coding: utf-8 -*-
# @Author  : Jiang Yuan
# @Time    : 2021/8/22 11:12
# @Function:
import json
import os
import difflib
from xml.dom.minidom import parse
from tqdm import tqdm
import re
from collections import OrderedDict

def get_id_dict(source_path):
    ids = os.listdir(source_path)
    id_dict = {}
    for id in ids:
        id_dict[id] = id
    return id_dict

def get_syn_vul_statement(synthetic_path, line_numbers, id_dict, curr_id, file_name):
    line_statement = {}
    if curr_id in id_dict.keys():
        if file_name in os.listdir(os.path.join(synthetic_path, id_dict[curr_id])):
            with open(os.path.join(synthetic_path, id_dict[curr_id], file_name), 'r', encoding='utf8', errors='ignore') as f:
                file_content = f.readlines()
            line_dict = {}
            for line in line_numbers:
                if int(line) > 0:
                    line_statement[line] = file_content[int(line)-1]
                else:
                    line_statement[line] = None
    else:
        for line in line_numbers:
            line_statement[line] = None
    return line_statement

def obtain_synthetic_vulInfo():
    '''
    1 合成项目的vul info信息
    :return:
    '''
    path='../resources/fine_label/SARD_testcaseinfo.xml'
    source_path = '../resources/Program/Source_code'
    id_dict = get_id_dict(source_path)
    domTree = parse(path)
    # 文档根元素
    rootNode = domTree.documentElement
    print(rootNode.nodeName)

    # 所有Test_cases
    test_cases = rootNode.getElementsByTagName("testcase")
    test_cases_info_dict={}
    print("****所有Test Cases的信息****")
    # ids = []
    for test_case in test_cases:
        if test_case.hasAttribute("id"):
            id = test_case.getAttribute("id")
            # print("id", id)
            # ids.append(int(id))
            test_case_info={}
            # name 元素
            file_paths = test_case.getElementsByTagName("file")
            # print(file_path.nodeName, ":", file_path.getAttribute('path'))
            # 遍历漏洞对应的文件
            for file_path in file_paths:
                flaw_lines = file_path.getElementsByTagName("flaw")
                line_numbers=[]
                # 遍历漏洞文件对应的漏洞行

                for flaw_line in flaw_lines:
                    line = flaw_line.getAttribute('line')
                    # 漏洞行号
                    line_numbers.append(line)

                mix_lines = file_path.getElementsByTagName('mixed')
                for mix_line in mix_lines:
                    line = mix_line.getAttribute('line')
                    # 漏洞行号
                    line_numbers.append(line)
                file_name = file_path.getAttribute('path').split('/')[-1]
                line_statement = get_syn_vul_statement(source_path, line_numbers, id_dict, id, file_name)
                test_case_info[file_path.getAttribute('path')]=line_statement

            test_cases_info_dict[id] = test_case_info

    for curr_id in id_dict.keys():
        # if curr_id 不是以cve开始
        if not curr_id.startswith('CVE-'):
            vul_info_file_name = 'vul_info.txt'
            with open(os.path.join(source_path, id_dict[curr_id], vul_info_file_name), 'w') as vul_info_file:
                json.dump(test_cases_info_dict[str(curr_id)], vul_info_file)
            print('Success deal with %s' % curr_id)

    print('Success !')

def get_real_vul_statement(vul_line, vul_content):
    line_statements = {}
    for line in vul_line:
        statement = vul_content[int(line) - 1]
        line_statements[line] = statement
    return line_statements

def obtain_real_vulInfo():
    '''
    2 真实项目的vul info信息
    :return:
    '''
    # dir_name='../../data/programs/real_world_programs_func_info'
    source_path = '../resources/Program/Source_code'
    id_dict = get_id_dict(source_path)
    real_id_dict = {key: value for key, value in id_dict.items() if key.startswith('CVE-')}

    for id in real_id_dict.keys():
        vul_dir = os.path.join(source_path, id)
        vul_info = {}
        for file in os.listdir(vul_dir):
            # （1）包含漏洞文件
            if 'VULN' in file:
                vul_file_path = os.path.join(vul_dir, file)
                patch_file_path = vul_file_path.replace('VULN', 'PATCHED')
                if os.path.exists(patch_file_path): # （2）包含补丁文件
                    with open(vul_file_path, 'r', encoding='utf8', errors='ignore') as f:
                        vul_content = f.readlines()
                    with open(patch_file_path, 'r', encoding='utf8', errors='ignore') as f:
                        patch_content = f.readlines()
                    # （3）计算差异文件
                    diff = difflib.unified_diff(
                        vul_content,
                        patch_content,
                        lineterm='')
                    # print('\n'.join(diff))
                    # print('\n'.join(diff))

                    # （4）根据差异文件得到漏洞语句所在行,以及每行所对应的内容
                    count = 0
                    source_start_line = -1
                    vul_line = []
                    for line in diff:
                        tmpline = line[1:]
                        if line.startswith('---') or line.startswith('+'):
                            continue

                        # 只用正则判断单行注释会有识别不出来的情况
                        if re.match("(?<!:)\\/\\/.*|\\/\\*(\\s|.)*?\\*\\/",tmpline.strip()):
                            count+=1
                            continue
                        if line.startswith('@@ '):
                            count = 0
                            line=line[3:-3]
                            # line = re.findall(r"@@(.+?)@@", line)  # @@ -78,7 +79,11 @@
                            source_info, target_info=line.split(' ') # -78,7
                            source_start_line, source_line_num = source_info[1:].split(',')
                            target_start_line, target_line_num = target_info[1:].split(',')
                            continue
                        if line.startswith('-') and line.rstrip()!="-":
                            vul_line.append(int(source_start_line) + count)
                            # print(line, source_start_line, count)
                        if line.startswith('+'): # 添加的句子不能计数count
                            continue
                        count += 1

                    # 漏洞行对应的漏洞语句
                    line_statement = get_real_vul_statement(vul_line, vul_content)
                    vul_info[file] = line_statement

        vul_info_file_name = 'vul_info.txt'
        vul_info_path = os.path.join(vul_dir, vul_info_file_name)
        with open(vul_info_path, 'w') as vul_info_file:
            json.dump(vul_info, vul_info_file)

def removeComments(string):
    string = re.sub(re.compile("/\*.*?\*/",re.DOTALL ) ,"" ,string) # remove all occurrences streamed comments (/*COMMENT */) from string
    string = re.sub(re.compile("//.*?\n" ) ,"" ,string) # remove all occurrence single-line comments (//COMMENT\n ) from string
    return string

def label():
    # path=r'F:\ly\code\VulDeeLocator_source\resources\Dataset\locator_slice\pointslice\25\pointersuse_slices.txt'
    # with open(path,'r') as f:
    #     file_content=f.read()
    # inst_list=file_content.split('------------------------------\n')
    # print(inst_list[0])
    # print(len(inst_list))
    slice_path = '../resources/cwe_slice_graphs'
    saved_path ='../resources/cwe_labelled_slice_graphs'
    vul_info_file_name = 'vul_info.txt'
    source_path = '../resources/Program/Source_code'

    file_names = os.listdir(slice_path)
    for file_name in file_names:
        if not '_slices.txt' in file_name:
            continue

        target_file_path = os.path.join(saved_path, file_name)
        label_file_path = os.path.join(saved_path, os.path.splitext(file_name)[0]+'_label.json')

        target_file = open(target_file_path, 'w')
        label_file = open(label_file_path,'w')
        label_file_dict = {}

        print("processing %s" % file_name)
        path = os.path.join(slice_path, file_name)
        with open(path, 'r') as f:
            file_content = f.read()
        inst_list = file_content.split('------------------------------\n')
        for index, slice_content in tqdm(enumerate(inst_list)):
            labeled_content = ""
            slice_list = slice_content.split('\n')
            label_text_list = []
            tmp_slice = slice_list[0].split(' ')
            if len(tmp_slice) < 2:
                # print(tmp_slice)
                continue
            tmp_path = tmp_slice[1]
            temp_content = [] # 存储的tuple （行号，内容）
            for slice_line in slice_list[1:]: # 第二行，到最后一行
                tmp_line_slices = slice_line.split()
                if len(tmp_line_slices) > 1:
                    temp_content.append((tmp_line_slices[-1], "".join(tmp_line_slices[:-1])))

            vul_file_name = tmp_path.split('/')[-1]
            id = tmp_path.split('/')[-2]
            vul_info_file_path = os.path.join(source_path, id, vul_info_file_name) #
            if vul_info_file_name not in os.listdir(os.path.join(source_path, id)):
                continue
            with open(vul_info_file_path, 'r') as vul_info_file:
                vul_info_dict = json.load(vul_info_file)

            # key 是 filepath
            for key in vul_info_dict.keys():
                vul_info_line_statement_dict = vul_info_dict[key]
                # len == 0 代表当前文件不包含漏洞
                if len(vul_info_line_statement_dict) == 0:
                    continue
                for i, (line_number, line_content) in enumerate(temp_content):
                    if line_number in vul_info_line_statement_dict.keys():
                        # label_text_list.append(line_number)
                        compared_content = ""
                        orig_content = removeComments(vul_info_line_statement_dict[line_number])
                        if orig_content != None:
                            compared_content = "".join(orig_content.split())
                        if compared_content == line_content:
                            label_text_list.append(str(i + 1))
            if label_text_list != []:
                label_text_list.sort()
                # print(label_text_list)
                label_text = '[' + ",".join(label_text_list) + ']\n'
            else:
                label_text = '[0]\n'
            labeled_content = labeled_content + slice_content + label_text + '------------------------------\n'
            target_file.write(labeled_content)
            # key: id+文件路径+切片标准+所在行， value：label
            label_file_dict[slice_list[0]] = label_text
        target_file.close()
        json.dump(label_file_dict, label_file)
        label_file.close()



if __name__ == '__main__':
    # obtain_synthetic_vulInfo()
    # obtain_real_vulInfo()
    label()

